{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zadanie: Wyznaczenie 3 najpopularniejszych języków dla danej kategorii dla wszystkich aplikacji których cena jest większa bądź równa średniej cenie dla danej aplikacji\n",
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('/user/wawrzynimaci/data/iosdata.csv', header='true', inferSchema='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schemat danych oraz kolumny "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.schema)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Liczba początkowa rekordów wczytanej bazy: {data.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## W tym kroku tworzę df, która będzie przechowywała średnią cenę aplikacji dla każdej kategorii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "avgCategoryPrice = data.filter(\"Price_USD is not NULL\").where(data.Price_USD >= 0).groupBy('Primary_Genre').avg('Price_USD')\n",
    "avgCategoryPrice = avgCategoryPrice.withColumnRenamed(\"avg(Price_USD)\", \"AvgVal\").withColumnRenamed(\"Primary_Genre\", \"Genre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Średnie cene dla każdej kategorii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgCategoryPrice.show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teraz usuwamy wszystkie te wartości, których cena jest mniejsza niż średnia cena dla kategorii "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGreaterAvge = avgCategoryPrice.join(data, avgCategoryPrice.Genre == data.Primary_Genre)\n",
    "dataGreaterAvge = dataGreaterAvge.where(dataGreaterAvge.Price_USD >= dataGreaterAvge.AvgVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Liczba rekordów po usunięciu wartości, których cena była mniejsza od średniej ceny dla danej kategorii:')\n",
    "print(f'{dataGreaterAvge.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teraz tworzymy nowy DF na którym będziemy dalej pracować i analizować dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctData = dataGreaterAvge.select('Price_USD','Primary_Genre','Languages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Liczba rekordów po skopiowaniu df:')\n",
    "print(f'{correctData.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozbijam teraz tablicę N elementową na N wierwszy i czyszczę błędne spacje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, split, regexp_replace\n",
    "explodeLanguages = correctData.select(correctData.Primary_Genre, explode(split(regexp_replace(correctData.Languages,\"[\\\\[|\\\\'|\\\\]]\",\"\"),\",\")))\n",
    "explodeLanguages = explodeLanguages.withColumnRenamed(\"col\", \"Language\")\n",
    "explodeLanguages.columns\n",
    "\n",
    "correctExplodeLanguages = explodeLanguages.select(explodeLanguages.Primary_Genre, regexp_replace(explodeLanguages.Language, \" | \", \"\")).withColumnRenamed(\"regexp_replace(Language,  | , )\", \"Language\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zliczanie języków - zlicza dla danej kategorii liczbę wystąpień danego języka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_count = correctExplodeLanguages.groupBy(correctExplodeLanguages.Primary_Genre, correctExplodeLanguages.Language).count().orderBy(correctExplodeLanguages.Primary_Genre, F.desc('count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pobranie 3 języków które najczęściej występują dla każdej kategorii "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window as W\n",
    "ranked =  languages_count.withColumn('rank', F.rank().over(W.partitionBy('Primary_Genre').orderBy(\"Primary_Genre\", F.desc('count'))))\n",
    "ranked.where(ranked.rank <= 3).orderBy(\"Primary_Genre\", F.desc('count')).show(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[IPyKernel] PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
